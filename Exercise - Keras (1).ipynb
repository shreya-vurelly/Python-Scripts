{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise - Neural Networks using Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set for this exercise is from the banking industry. It contains data about the home loans of 2,500 bank clients. Each row represents a single loan. The columns include the characteristics of the client who used a loan. This is a binary classification task: predict whether a loan will be bad or not (1=Yes, 0=No). This is an important task for banks to prevent bad loans from being issued."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of Variables\n",
    "\n",
    "The description of variables are provided in \"Loan - Data Dictionary.docx\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "\n",
    "Use the **loan.csv** data set and build a model to predict **BAD**. \n",
    "\n",
    "Since you have a relatively small data set, I recommend using cross-validation to evaluate your accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BAD</th>\n",
       "      <th>LOAN</th>\n",
       "      <th>MORTDUE</th>\n",
       "      <th>VALUE</th>\n",
       "      <th>REASON</th>\n",
       "      <th>JOB</th>\n",
       "      <th>YOJ</th>\n",
       "      <th>DEROG</th>\n",
       "      <th>DELINQ</th>\n",
       "      <th>CLAGE</th>\n",
       "      <th>NINQ</th>\n",
       "      <th>CLNO</th>\n",
       "      <th>DEBTINC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>25900</td>\n",
       "      <td>61064.0</td>\n",
       "      <td>94714.0</td>\n",
       "      <td>DebtCon</td>\n",
       "      <td>Office</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98.809375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>34.565944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>26100</td>\n",
       "      <td>113266.0</td>\n",
       "      <td>182082.0</td>\n",
       "      <td>DebtCon</td>\n",
       "      <td>Sales</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>304.852469</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>33.193949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>50000</td>\n",
       "      <td>220528.0</td>\n",
       "      <td>300900.0</td>\n",
       "      <td>HomeImp</td>\n",
       "      <td>Self</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>22400</td>\n",
       "      <td>51470.0</td>\n",
       "      <td>68139.0</td>\n",
       "      <td>DebtCon</td>\n",
       "      <td>Mgr</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.168696</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>37.952180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>20900</td>\n",
       "      <td>62615.0</td>\n",
       "      <td>87904.0</td>\n",
       "      <td>DebtCon</td>\n",
       "      <td>Office</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>177.864849</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>36.831076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   BAD   LOAN   MORTDUE     VALUE   REASON     JOB   YOJ  DEROG  DELINQ  \\\n",
       "0    0  25900   61064.0   94714.0  DebtCon  Office   2.0    0.0     0.0   \n",
       "1    0  26100  113266.0  182082.0  DebtCon   Sales  18.0    0.0     0.0   \n",
       "2    1  50000  220528.0  300900.0  HomeImp    Self   5.0    0.0     0.0   \n",
       "3    1  22400   51470.0   68139.0  DebtCon     Mgr   9.0    0.0     0.0   \n",
       "4    0  20900   62615.0   87904.0  DebtCon  Office   5.0    NaN     NaN   \n",
       "\n",
       "        CLAGE  NINQ  CLNO    DEBTINC  \n",
       "0   98.809375   0.0  23.0  34.565944  \n",
       "1  304.852469   1.0  31.0  33.193949  \n",
       "2    0.000000   0.0   2.0        NaN  \n",
       "3   31.168696   2.0   8.0  37.952180  \n",
       "4  177.864849   NaN  15.0  36.831076  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We will predict the \"price\" value in the data set:\n",
    "\n",
    "loan = pd.read_csv(\"loan_keras.csv\")\n",
    "loan.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data (train/test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(loan, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep\n",
    "\n",
    "Perform your data prep here. You can use pipelines like we do in the tutorials. Otherwise, feel free to use your own data prep steps. Eventually, you should do the following at a minimum:<br>\n",
    "- Separate inputs from target<br>\n",
    "- Impute/remove missing values<br>\n",
    "- Standardize the continuous variables<br>\n",
    "- One-hot encode categorical variables<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate the target variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target = train['BAD']\n",
    "test_target = test['BAD']\n",
    "\n",
    "train_inputs = train.drop(['BAD'], axis=1)\n",
    "test_inputs = test.drop(['BAD'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering: Derive a new column\n",
    "\n",
    "Examples:\n",
    "- Ratio of delinquent to total number of credit lines\n",
    "- Ratio of loan to value of current property\n",
    "- Convert yr_renovated to a binary variable (i.e., renovated or not)\n",
    "- (etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_col(df):\n",
    "    \n",
    "    #Create a copy so that we don't overwrite the existing dataframe\n",
    "    df1 = df.copy()\n",
    "\n",
    "    # Use the formula, though fill in 0s when the value is 0/0 (because 0/0 generates \"nan\" values)\n",
    "    df1['deliq_ratio'] = (df1['DELINQ']/df1['CLNO']).fillna(0)\n",
    "\n",
    "    # Replace the infinity values with 1 (because a value divided by 0 generates infinity)\n",
    "    df1['deliq_ratio'].replace(np.inf, 1, inplace=True)\n",
    "\n",
    "    return df1[['deliq_ratio']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>deliq_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2055</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1961</th>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1864</th>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2326</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1638</th>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>0.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      deliq_ratio\n",
       "2055     0.000000\n",
       "1961     0.300000\n",
       "1864     0.041667\n",
       "2326     0.000000\n",
       "461      0.000000\n",
       "...           ...\n",
       "1638     0.125000\n",
       "1095     0.181818\n",
       "1130     0.000000\n",
       "1294     0.000000\n",
       "860      0.000000\n",
       "\n",
       "[2000 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_col(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Identify the numeric, binary, and categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the numerical columns\n",
    "numeric_columns = train_inputs.select_dtypes(include=[np.number]).columns.to_list()\n",
    "\n",
    "# Identify the categorical columns\n",
    "categorical_columns = train_inputs.select_dtypes('object').columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LOAN',\n",
       " 'MORTDUE',\n",
       " 'VALUE',\n",
       " 'YOJ',\n",
       " 'DEROG',\n",
       " 'DELINQ',\n",
       " 'CLAGE',\n",
       " 'NINQ',\n",
       " 'CLNO',\n",
       " 'DEBTINC']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['REASON', 'JOB']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_eng_columns = ['DELINQ', 'CLNO']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(steps=[\n",
    "                ('imputer', SimpleImputer(strategy='median')),\n",
    "                ('scaler', StandardScaler())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='unknown')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline for the transformed column here\n",
    "\n",
    "my_new_column = Pipeline(steps=[('my_new_column', FunctionTransformer(new_col)),\n",
    "                               ('scaler', StandardScaler())])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer([\n",
    "        ('num', numeric_transformer, numeric_columns),\n",
    "        ('cat', categorical_transformer, categorical_columns),\n",
    "        ('trans', my_new_column, feat_eng_columns)],   \n",
    "        remainder='passthrough')\n",
    "\n",
    "#passtrough is an optional step. You don't have to use it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform: fit_transform() for TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.04111078,  0.6878524 ,  0.85091391, ...,  0.        ,\n",
       "         0.        , -0.42081285],\n",
       "       [-0.28532644, -0.52374577, -0.00483295, ...,  0.        ,\n",
       "         0.        ,  3.61741439],\n",
       "       [-0.49898075, -0.60339785, -0.57929256, ...,  0.        ,\n",
       "         0.        ,  0.14005205],\n",
       "       ...,\n",
       "       [-0.20520607, -0.8316353 , -0.79774855, ...,  0.        ,\n",
       "         0.        , -0.42081285],\n",
       "       [-0.45446944,  1.82868782,  1.33923641, ...,  0.        ,\n",
       "         0.        , -0.42081285],\n",
       "       [-0.30313096, -0.0781773 , -0.20951181, ...,  0.        ,\n",
       "         0.        , -0.42081285]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit and transform the train data\n",
    "train_x = preprocessor.fit_transform(train_inputs)\n",
    "\n",
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 21)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tranform: transform() for TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.07966635,  0.38294162,  0.31640967, ...,  0.        ,\n",
       "         0.        , -0.42081285],\n",
       "       [ 0.33783199,  0.59525334,  0.4202283 , ...,  1.        ,\n",
       "         0.        , -0.42081285],\n",
       "       [-0.32093549,  0.42863133,  0.12227435, ...,  0.        ,\n",
       "         0.        , -0.42081285],\n",
       "       ...,\n",
       "       [-0.58800339, -0.65204285, -0.73238892, ...,  0.        ,\n",
       "         0.        , -0.42081285],\n",
       "       [-0.82836449, -0.33280126, -0.49771342, ...,  0.        ,\n",
       "         0.        , -0.42081285],\n",
       "       [ 0.69392251,  0.9629992 ,  1.3954629 , ...,  0.        ,\n",
       "         0.        , -0.42081285]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform the test data\n",
    "test_x = preprocessor.transform(test_inputs)\n",
    "\n",
    "test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 21)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate the Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DummyClassifier(strategy=&#x27;most_frequent&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DummyClassifier</label><div class=\"sk-toggleable__content\"><pre>DummyClassifier(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DummyClassifier(strategy='most_frequent')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "\n",
    "dummy_clf.fit(train_x, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Train Accuracy: 0.5995\n",
      "Baseline Test Accuracy: 0.58\n"
     ]
    }
   ],
   "source": [
    "#Baseline Train Accuracy\n",
    "dummy_train_pred = dummy_clf.predict(train_x)\n",
    "\n",
    "baseline_train_acc = accuracy_score(train_target, dummy_train_pred)\n",
    "\n",
    "print('Baseline Train Accuracy: {}' .format(baseline_train_acc))\n",
    "\n",
    "#Baseline Test Accuracy\n",
    "dummy_test_pred = dummy_clf.predict(test_x)\n",
    "\n",
    "baseline_test_acc = accuracy_score(test_target, dummy_test_pred)\n",
    "\n",
    "print('Baseline Test Accuracy: {}' .format(baseline_test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a shallow (one-layer) Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 21)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the model: for multi-class\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(keras.layers.Input(shape=21))\n",
    "model.add(keras.layers.Dense(21, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "\n",
    "#Optimizer:\n",
    "adam = keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a deep (multi-layered) Keras model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "20/20 [==============================] - 1s 15ms/step - loss: 0.5902 - accuracy: 0.6920 - val_loss: 0.5210 - val_accuracy: 0.7460\n",
      "Epoch 2/20\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5133 - accuracy: 0.7540 - val_loss: 0.4951 - val_accuracy: 0.7580\n",
      "Epoch 3/20\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4930 - accuracy: 0.7630 - val_loss: 0.4851 - val_accuracy: 0.7680\n",
      "Epoch 4/20\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4836 - accuracy: 0.7710 - val_loss: 0.4782 - val_accuracy: 0.7740\n",
      "Epoch 5/20\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4774 - accuracy: 0.7690 - val_loss: 0.4738 - val_accuracy: 0.7680\n",
      "Epoch 6/20\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4699 - accuracy: 0.7710 - val_loss: 0.4684 - val_accuracy: 0.7740\n",
      "Epoch 7/20\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4669 - accuracy: 0.7760 - val_loss: 0.4648 - val_accuracy: 0.7840\n",
      "Epoch 8/20\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4556 - accuracy: 0.7860 - val_loss: 0.4642 - val_accuracy: 0.7900\n",
      "Epoch 9/20\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4483 - accuracy: 0.7900 - val_loss: 0.4507 - val_accuracy: 0.7960\n",
      "Epoch 10/20\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4432 - accuracy: 0.7940 - val_loss: 0.4598 - val_accuracy: 0.7800\n",
      "Epoch 11/20\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4364 - accuracy: 0.7960 - val_loss: 0.4475 - val_accuracy: 0.7880\n",
      "Epoch 12/20\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4345 - accuracy: 0.8005 - val_loss: 0.4356 - val_accuracy: 0.8040\n",
      "Epoch 13/20\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4264 - accuracy: 0.8035 - val_loss: 0.4476 - val_accuracy: 0.7860\n",
      "Epoch 14/20\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4199 - accuracy: 0.8065 - val_loss: 0.4379 - val_accuracy: 0.7980\n",
      "Epoch 15/20\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4178 - accuracy: 0.8095 - val_loss: 0.4435 - val_accuracy: 0.7840\n",
      "Epoch 16/20\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4131 - accuracy: 0.8080 - val_loss: 0.4273 - val_accuracy: 0.8120\n",
      "Epoch 17/20\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4034 - accuracy: 0.8250 - val_loss: 0.4403 - val_accuracy: 0.8100\n",
      "Epoch 18/20\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4097 - accuracy: 0.8155 - val_loss: 0.4282 - val_accuracy: 0.8120\n",
      "Epoch 19/20\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.3973 - accuracy: 0.8250 - val_loss: 0.4257 - val_accuracy: 0.8080\n",
      "Epoch 20/20\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3917 - accuracy: 0.8295 - val_loss: 0.4246 - val_accuracy: 0.8120\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "\n",
    "history = model.fit(train_x, train_target, \n",
    "                    validation_data=(test_x, test_target), \n",
    "                    epochs=20, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.38676244020462036, 0.8270000219345093]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train values\n",
    "\n",
    "train_scores = model.evaluate(train_x, train_target, verbose=0)\n",
    "\n",
    "train_scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.39\n",
      "Train accuracy: 82.70%\n"
     ]
    }
   ],
   "source": [
    "# Print the values\n",
    "\n",
    "print(f\"Train {model.metrics_names[0]}: {train_scores[0]:.2f}\")\n",
    "\n",
    "print(f\"Train {model.metrics_names[1]}: {train_scores[1]*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4245983958244324, 0.8119999766349792]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test values\n",
    "\n",
    "test_scores = model.evaluate(test_x, test_target, verbose=0)\n",
    "\n",
    "test_scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.42\n",
      "Test accuracy: 81.20%\n"
     ]
    }
   ],
   "source": [
    "# Print the values\n",
    "\n",
    "print(f\"Test {model.metrics_names[0]}: {test_scores[0]:.2f}\")\n",
    "\n",
    "print(f\"Test {model.metrics_names[1]}: {test_scores[1]*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optional: try different activation functions, optimizers, or configurations (such as wide and deep) to build other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.04111078,  0.6878524 ],\n",
       "       [-0.28532644, -0.52374577],\n",
       "       [-0.49898075, -0.60339785],\n",
       "       ...,\n",
       "       [-0.20520607, -0.8316353 ],\n",
       "       [-0.45446944,  1.82868782],\n",
       "       [-0.30313096, -0.0781773 ]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select the first two columns: longitude and latitude\n",
    "#(WHY: because lat and lon are good and important predictors)\n",
    "\n",
    "train_lon_lat = train_x[:,:2]\n",
    "\n",
    "train_lon_lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lon_lat = test_x[:,:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "\n",
    "input1 = keras.layers.Input(shape=2)\n",
    "input2 = keras.layers.Input(shape=21)\n",
    "\n",
    "hidden1 = keras.layers.Dense(21, activation='relu')(input2)\n",
    "hidden2 = keras.layers.Dense(21, activation='relu')(hidden1)\n",
    "hidden3 = keras.layers.Dense(21, activation='relu')(hidden2)\n",
    "\n",
    "concat = keras.layers.Concatenate()([input1, hidden3])\n",
    "\n",
    "#final layer: there has to be 4 nodes with softmax (because we have 4 categories)\n",
    "output = keras.layers.Dense(1, activation='sigmoid')(concat)\n",
    "\n",
    "model = keras.Model(inputs =[input1, input2], outputs = output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "\n",
    "#Optimizer:\n",
    "adam = keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "20/20 [==============================] - 1s 15ms/step - loss: 0.6259 - accuracy: 0.6570 - val_loss: 0.5483 - val_accuracy: 0.7340\n",
      "Epoch 2/20\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5190 - accuracy: 0.7585 - val_loss: 0.4899 - val_accuracy: 0.7560\n",
      "Epoch 3/20\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4938 - accuracy: 0.7615 - val_loss: 0.4769 - val_accuracy: 0.7680\n",
      "Epoch 4/20\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4747 - accuracy: 0.7770 - val_loss: 0.4661 - val_accuracy: 0.7720\n",
      "Epoch 5/20\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4645 - accuracy: 0.7820 - val_loss: 0.4573 - val_accuracy: 0.7800\n",
      "Epoch 6/20\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4553 - accuracy: 0.7875 - val_loss: 0.4608 - val_accuracy: 0.7780\n",
      "Epoch 7/20\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4337 - accuracy: 0.8035 - val_loss: 0.4660 - val_accuracy: 0.7660\n",
      "Epoch 8/20\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4211 - accuracy: 0.8105 - val_loss: 0.4449 - val_accuracy: 0.7960\n",
      "Epoch 9/20\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3963 - accuracy: 0.8280 - val_loss: 0.4318 - val_accuracy: 0.7860\n",
      "Epoch 10/20\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.3776 - accuracy: 0.8400 - val_loss: 0.4372 - val_accuracy: 0.7920\n",
      "Epoch 11/20\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3611 - accuracy: 0.8490 - val_loss: 0.4458 - val_accuracy: 0.8020\n",
      "Epoch 12/20\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.3559 - accuracy: 0.8470 - val_loss: 0.4577 - val_accuracy: 0.8080\n",
      "Epoch 13/20\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.3347 - accuracy: 0.8590 - val_loss: 0.4202 - val_accuracy: 0.8100\n",
      "Epoch 14/20\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3257 - accuracy: 0.8550 - val_loss: 0.4630 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.3054 - accuracy: 0.8695 - val_loss: 0.4556 - val_accuracy: 0.8040\n",
      "Epoch 16/20\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.2909 - accuracy: 0.8730 - val_loss: 0.4765 - val_accuracy: 0.8080\n",
      "Epoch 17/20\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2697 - accuracy: 0.8860 - val_loss: 0.4757 - val_accuracy: 0.8100\n",
      "Epoch 18/20\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.2648 - accuracy: 0.8935 - val_loss: 0.4879 - val_accuracy: 0.8200\n",
      "Epoch 19/20\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.2784 - accuracy: 0.8855 - val_loss: 0.4857 - val_accuracy: 0.8140\n",
      "Epoch 20/20\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2426 - accuracy: 0.8945 - val_loss: 0.4897 - val_accuracy: 0.8080\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "\n",
    "history = model.fit((train_lon_lat, train_x), train_target, \n",
    "                    validation_data=((test_lon_lat, test_x), test_target), \n",
    "                    epochs=20, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.21594728529453278, 0.9150000214576721]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train values\n",
    "\n",
    "train_scores = model.evaluate((train_lon_lat, train_x), train_target, verbose=0)\n",
    "\n",
    "train_scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.22\n",
      "Train accuracy: 91.50%\n"
     ]
    }
   ],
   "source": [
    "# Print the values\n",
    "\n",
    "print(f\"Train {model.metrics_names[0]}: {train_scores[0]:.2f}\")\n",
    "\n",
    "print(f\"Train {model.metrics_names[1]}: {train_scores[1]*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.48974159359931946, 0.8080000281333923]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test values\n",
    "\n",
    "test_scores = model.evaluate((test_lon_lat, test_x), test_target, verbose=0)\n",
    "\n",
    "test_scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.49\n",
      "Test accuracy: 80.80%\n"
     ]
    }
   ],
   "source": [
    "# Print the values\n",
    "\n",
    "print(f\"Test {model.metrics_names[0]}: {test_scores[0]:.2f}\")\n",
    "\n",
    "print(f\"Test {model.metrics_names[1]}: {test_scores[1]*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "nav_menu": {
   "height": "279px",
   "width": "309px"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
