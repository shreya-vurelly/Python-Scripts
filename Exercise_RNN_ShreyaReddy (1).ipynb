{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise - RNN Classification\n",
    "\n",
    "In this notebook, we will perform a classification task using RNNs (i.e., a sequence to value prediction). We have hourly power consumption of households for 12 hours. Based on this, we will determine whether the power grid is strained (1) or not (0). \n",
    "\n",
    "Therefore, use the columns from `Hour 0` to `Hour 11` to predict the `target` column in the `power.csv` data set.\n",
    "\n",
    "Hint1: Use Tutorial 1 for help.\n",
    "\n",
    "Hint2: Don't forget to adjust the number of neurons in the input layers correctly. Otherwise, you will run into errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(39)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hour 0</th>\n",
       "      <th>Hour 1</th>\n",
       "      <th>Hour 2</th>\n",
       "      <th>Hour 3</th>\n",
       "      <th>Hour 4</th>\n",
       "      <th>Hour 5</th>\n",
       "      <th>Hour 6</th>\n",
       "      <th>Hour 7</th>\n",
       "      <th>Hour 8</th>\n",
       "      <th>Hour 9</th>\n",
       "      <th>Hour 10</th>\n",
       "      <th>Hour 11</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.550633</td>\n",
       "      <td>2.523400</td>\n",
       "      <td>2.582333</td>\n",
       "      <td>2.541667</td>\n",
       "      <td>2.475733</td>\n",
       "      <td>2.476233</td>\n",
       "      <td>2.455800</td>\n",
       "      <td>2.447200</td>\n",
       "      <td>2.441733</td>\n",
       "      <td>3.146133</td>\n",
       "      <td>2.661733</td>\n",
       "      <td>2.576000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.596933</td>\n",
       "      <td>1.619567</td>\n",
       "      <td>2.473733</td>\n",
       "      <td>2.731133</td>\n",
       "      <td>2.431133</td>\n",
       "      <td>2.479667</td>\n",
       "      <td>1.690200</td>\n",
       "      <td>1.332133</td>\n",
       "      <td>1.375167</td>\n",
       "      <td>1.050900</td>\n",
       "      <td>0.585900</td>\n",
       "      <td>2.651900</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.534933</td>\n",
       "      <td>0.540467</td>\n",
       "      <td>0.575367</td>\n",
       "      <td>0.526500</td>\n",
       "      <td>0.521900</td>\n",
       "      <td>0.565333</td>\n",
       "      <td>1.426467</td>\n",
       "      <td>0.602067</td>\n",
       "      <td>0.547433</td>\n",
       "      <td>0.525067</td>\n",
       "      <td>1.270300</td>\n",
       "      <td>0.393767</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.085867</td>\n",
       "      <td>0.651233</td>\n",
       "      <td>0.634600</td>\n",
       "      <td>0.653000</td>\n",
       "      <td>0.646067</td>\n",
       "      <td>0.628400</td>\n",
       "      <td>0.611067</td>\n",
       "      <td>0.612533</td>\n",
       "      <td>0.660100</td>\n",
       "      <td>0.606067</td>\n",
       "      <td>1.471867</td>\n",
       "      <td>0.834533</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.456000</td>\n",
       "      <td>0.286300</td>\n",
       "      <td>0.310833</td>\n",
       "      <td>0.250933</td>\n",
       "      <td>0.277667</td>\n",
       "      <td>0.308633</td>\n",
       "      <td>0.610400</td>\n",
       "      <td>1.563533</td>\n",
       "      <td>1.421867</td>\n",
       "      <td>3.324400</td>\n",
       "      <td>3.207567</td>\n",
       "      <td>1.425433</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Hour 0    Hour 1    Hour 2    Hour 3    Hour 4    Hour 5    Hour 6  \\\n",
       "0  2.550633  2.523400  2.582333  2.541667  2.475733  2.476233  2.455800   \n",
       "1  1.596933  1.619567  2.473733  2.731133  2.431133  2.479667  1.690200   \n",
       "2  0.534933  0.540467  0.575367  0.526500  0.521900  0.565333  1.426467   \n",
       "3  1.085867  0.651233  0.634600  0.653000  0.646067  0.628400  0.611067   \n",
       "4  0.456000  0.286300  0.310833  0.250933  0.277667  0.308633  0.610400   \n",
       "\n",
       "     Hour 7    Hour 8    Hour 9   Hour 10   Hour 11  target  \n",
       "0  2.447200  2.441733  3.146133  2.661733  2.576000       1  \n",
       "1  1.332133  1.375167  1.050900  0.585900  2.651900       1  \n",
       "2  0.602067  0.547433  0.525067  1.270300  0.393767       0  \n",
       "3  0.612533  0.660100  0.606067  1.471867  0.834533       0  \n",
       "4  1.563533  1.421867  3.324400  3.207567  1.425433       1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "power = pd.read_csv('power.csv')\n",
    "\n",
    "power.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1417, 13)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "power.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First 1000 days are for train\n",
    "train = power.iloc[:1000]\n",
    "\n",
    "# Remaining 417 days are for test\n",
    "test = power.iloc[-417:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 13)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(417, 13)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Input and Target values\n",
    "\n",
    "The first 12 columns (hourly data) will be input to predict the last column (i.e., target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first 12 columns (from 0 to 11) are inputs\n",
    "\n",
    "train_inputs = train.iloc[:,:12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add one more dimension to make it ready for RNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 12, 1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create an additional dimension for train\n",
    "\n",
    "train_x = np.array(train_inputs).reshape(1000,12,1)\n",
    "\n",
    "train_x.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The last column is TARGET\n",
    "\n",
    "train_target = train.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeat for TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(417, 13)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first 12 columns are inputs\n",
    "\n",
    "test_inputs = test.iloc[:,:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(417, 12, 1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create an additional dimension for test\n",
    "\n",
    "test_x = np.array(test_inputs).reshape(417,12,1)\n",
    "\n",
    "test_x.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The last column is TARGET\n",
    "\n",
    "test_target = test.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DummyClassifier(strategy=&#x27;most_frequent&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DummyClassifier</label><div class=\"sk-toggleable__content\"><pre>DummyClassifier(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DummyClassifier(strategy='most_frequent')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "\n",
    "dummy_clf.fit(train_x, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Train Accuracy: 0.505\n"
     ]
    }
   ],
   "source": [
    "#Baseline Train Accuracy\n",
    "dummy_train_pred = dummy_clf.predict(train_x)\n",
    "\n",
    "baseline_train_acc = accuracy_score(train_target, dummy_train_pred)\n",
    "\n",
    "print('Baseline Train Accuracy: {}' .format(baseline_train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Test Accuracy: 0.49640287769784175\n"
     ]
    }
   ],
   "source": [
    "#Baseline Test Accuracy\n",
    "dummy_test_pred = dummy_clf.predict(test_x)\n",
    "\n",
    "baseline_test_acc = accuracy_score(test_target, dummy_test_pred)\n",
    "\n",
    "print('Baseline Test Accuracy: {}' .format(baseline_test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a normal (cross-sectional) NN\n",
    "\n",
    "This model assumes that the data is NOT a time-series data set. It treats the data as cross-sectional and the columns being independent of each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    \n",
    "    keras.layers.Flatten(input_shape=[12, 1]),\n",
    "    keras.layers.Dense(12, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "32/32 [==============================] - 4s 26ms/step - loss: 0.4417 - accuracy: 0.7830 - val_loss: 0.4975 - val_accuracy: 0.7434\n",
      "Epoch 2/50\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.4276 - accuracy: 0.7830 - val_loss: 0.5098 - val_accuracy: 0.7722\n",
      "Epoch 3/50\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.4278 - accuracy: 0.7880 - val_loss: 0.5063 - val_accuracy: 0.7554\n",
      "Epoch 4/50\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.4110 - accuracy: 0.7930 - val_loss: 0.5952 - val_accuracy: 0.7146\n",
      "Epoch 5/50\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.4141 - accuracy: 0.8060 - val_loss: 0.5217 - val_accuracy: 0.7674\n",
      "Epoch 6/50\n",
      "32/32 [==============================] - 1s 16ms/step - loss: 0.4104 - accuracy: 0.7950 - val_loss: 0.5214 - val_accuracy: 0.7554\n",
      "Epoch 7/50\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.4060 - accuracy: 0.7990 - val_loss: 0.5547 - val_accuracy: 0.7170\n",
      "Epoch 8/50\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.4088 - accuracy: 0.7870 - val_loss: 0.5115 - val_accuracy: 0.7506\n",
      "Epoch 9/50\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.3897 - accuracy: 0.8110 - val_loss: 0.5419 - val_accuracy: 0.7506\n",
      "Epoch 10/50\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.3840 - accuracy: 0.8010 - val_loss: 0.5623 - val_accuracy: 0.7458\n",
      "Epoch 11/50\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.3997 - accuracy: 0.8150 - val_loss: 0.6493 - val_accuracy: 0.6954\n",
      "Epoch 12/50\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.3967 - accuracy: 0.8070 - val_loss: 0.7101 - val_accuracy: 0.7122\n",
      "Epoch 13/50\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.3884 - accuracy: 0.8150 - val_loss: 0.5362 - val_accuracy: 0.7482\n",
      "Epoch 14/50\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.3718 - accuracy: 0.8120 - val_loss: 0.5427 - val_accuracy: 0.7458\n",
      "Epoch 15/50\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.3414 - accuracy: 0.8360 - val_loss: 0.5626 - val_accuracy: 0.7314\n",
      "Epoch 16/50\n",
      "32/32 [==============================] - 0s 16ms/step - loss: 0.3655 - accuracy: 0.8330 - val_loss: 0.5495 - val_accuracy: 0.7458\n",
      "Epoch 17/50\n",
      "32/32 [==============================] - 0s 15ms/step - loss: 0.3556 - accuracy: 0.8350 - val_loss: 0.5489 - val_accuracy: 0.7746\n",
      "Epoch 18/50\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.3257 - accuracy: 0.8420 - val_loss: 0.5550 - val_accuracy: 0.7218\n",
      "Epoch 19/50\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.3229 - accuracy: 0.8430 - val_loss: 0.5761 - val_accuracy: 0.7506\n",
      "Epoch 20/50\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.3160 - accuracy: 0.8550 - val_loss: 0.5633 - val_accuracy: 0.7674\n",
      "Epoch 21/50\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.2936 - accuracy: 0.8650 - val_loss: 0.5996 - val_accuracy: 0.7314\n",
      "Epoch 22/50\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.3048 - accuracy: 0.8720 - val_loss: 0.6109 - val_accuracy: 0.7506\n",
      "Epoch 23/50\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.3045 - accuracy: 0.8720 - val_loss: 0.6631 - val_accuracy: 0.7290\n",
      "Epoch 24/50\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.2709 - accuracy: 0.8860 - val_loss: 0.6427 - val_accuracy: 0.7290\n",
      "Epoch 25/50\n",
      "32/32 [==============================] - 0s 15ms/step - loss: 0.3096 - accuracy: 0.8580 - val_loss: 0.6883 - val_accuracy: 0.7266\n",
      "Epoch 26/50\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.2813 - accuracy: 0.8700 - val_loss: 0.6378 - val_accuracy: 0.7362\n",
      "Epoch 27/50\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.2384 - accuracy: 0.8950 - val_loss: 0.6883 - val_accuracy: 0.7410\n",
      "Epoch 28/50\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.2701 - accuracy: 0.8760 - val_loss: 0.6226 - val_accuracy: 0.7338\n",
      "Epoch 29/50\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.2410 - accuracy: 0.9000 - val_loss: 0.6930 - val_accuracy: 0.7242\n",
      "Epoch 30/50\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.2699 - accuracy: 0.8820 - val_loss: 0.6438 - val_accuracy: 0.7290\n",
      "Epoch 31/50\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.2218 - accuracy: 0.9050 - val_loss: 0.6774 - val_accuracy: 0.7434\n",
      "Epoch 32/50\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.2109 - accuracy: 0.9210 - val_loss: 0.6761 - val_accuracy: 0.7530\n",
      "Epoch 33/50\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.2032 - accuracy: 0.9110 - val_loss: 0.7481 - val_accuracy: 0.7338\n",
      "Epoch 34/50\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.2107 - accuracy: 0.9100 - val_loss: 0.6894 - val_accuracy: 0.7434\n",
      "Epoch 35/50\n",
      "32/32 [==============================] - 0s 15ms/step - loss: 0.2630 - accuracy: 0.8960 - val_loss: 0.7156 - val_accuracy: 0.7266\n",
      "Epoch 36/50\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.2517 - accuracy: 0.8920 - val_loss: 0.6765 - val_accuracy: 0.7458\n",
      "Epoch 37/50\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.2304 - accuracy: 0.9040 - val_loss: 0.6538 - val_accuracy: 0.7698\n",
      "Epoch 38/50\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.1517 - accuracy: 0.9430 - val_loss: 0.7785 - val_accuracy: 0.7482\n",
      "Epoch 39/50\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.1480 - accuracy: 0.9470 - val_loss: 0.7741 - val_accuracy: 0.7410\n",
      "Epoch 40/50\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.1364 - accuracy: 0.9490 - val_loss: 0.8040 - val_accuracy: 0.7410\n",
      "Epoch 41/50\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.1360 - accuracy: 0.9480 - val_loss: 0.8026 - val_accuracy: 0.7362\n",
      "Epoch 42/50\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.1404 - accuracy: 0.9500 - val_loss: 0.8849 - val_accuracy: 0.7314\n",
      "Epoch 43/50\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.1694 - accuracy: 0.9260 - val_loss: 1.0147 - val_accuracy: 0.7290\n",
      "Epoch 44/50\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.2372 - accuracy: 0.9030 - val_loss: 0.8678 - val_accuracy: 0.7194\n",
      "Epoch 45/50\n",
      "32/32 [==============================] - 0s 15ms/step - loss: 0.1695 - accuracy: 0.9250 - val_loss: 0.8948 - val_accuracy: 0.7410\n",
      "Epoch 46/50\n",
      "32/32 [==============================] - 0s 15ms/step - loss: 0.1591 - accuracy: 0.9390 - val_loss: 0.8858 - val_accuracy: 0.7362\n",
      "Epoch 47/50\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.1474 - accuracy: 0.9410 - val_loss: 0.9014 - val_accuracy: 0.7338\n",
      "Epoch 48/50\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.1421 - accuracy: 0.9410 - val_loss: 1.0401 - val_accuracy: 0.7218\n",
      "Epoch 49/50\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.1375 - accuracy: 0.9420 - val_loss: 0.9711 - val_accuracy: 0.7098\n",
      "Epoch 50/50\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.1196 - accuracy: 0.9560 - val_loss: 0.9095 - val_accuracy: 0.7314\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(25)\n",
    "tf.random.set_seed(25)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Nadam(learning_rate=0.01)\n",
    "\n",
    "# If multiclass, use \"sparse_categorical_crossentropy\" as the loss function\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(train_x, train_target, epochs=50,\n",
    "                    validation_data=(test_x, test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5453658103942871, 0.7338129281997681]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_target, verbose=0)\n",
    "\n",
    "scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.55\n",
      "accuracy: 73.38%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a simple RNN with one layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 12\n",
    "n_inputs = 1\n",
    "\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    \n",
    "    keras.layers.SimpleRNN(32, input_shape=[n_steps, n_inputs]),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto')\n",
    "\n",
    "callback = [earlystop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "32/32 [==============================] - 1s 9ms/step - loss: 0.6180 - accuracy: 0.6670 - val_loss: 0.5670 - val_accuracy: 0.7410\n",
      "Epoch 2/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5050 - accuracy: 0.7460 - val_loss: 0.6311 - val_accuracy: 0.7002\n",
      "Epoch 3/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4916 - accuracy: 0.7490 - val_loss: 0.7483 - val_accuracy: 0.5899\n",
      "Epoch 4/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5318 - accuracy: 0.7340 - val_loss: 0.5594 - val_accuracy: 0.7098\n",
      "Epoch 5/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4787 - accuracy: 0.7650 - val_loss: 0.6162 - val_accuracy: 0.7074\n",
      "Epoch 6/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4764 - accuracy: 0.7680 - val_loss: 0.5171 - val_accuracy: 0.7194\n",
      "Epoch 7/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4642 - accuracy: 0.7710 - val_loss: 0.5167 - val_accuracy: 0.7626\n",
      "Epoch 8/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4626 - accuracy: 0.7550 - val_loss: 0.5134 - val_accuracy: 0.7506\n",
      "Epoch 9/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4697 - accuracy: 0.7490 - val_loss: 0.5578 - val_accuracy: 0.7194\n",
      "Epoch 10/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4600 - accuracy: 0.7570 - val_loss: 0.5008 - val_accuracy: 0.7578\n",
      "Epoch 11/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4526 - accuracy: 0.7650 - val_loss: 0.5087 - val_accuracy: 0.7458\n",
      "Epoch 12/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4683 - accuracy: 0.7570 - val_loss: 0.5077 - val_accuracy: 0.7386\n",
      "Epoch 13/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4530 - accuracy: 0.7620 - val_loss: 0.5463 - val_accuracy: 0.7170\n",
      "Epoch 14/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4587 - accuracy: 0.7650 - val_loss: 0.5212 - val_accuracy: 0.7290\n",
      "Epoch 15/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4520 - accuracy: 0.7580 - val_loss: 0.4984 - val_accuracy: 0.7626\n",
      "Epoch 16/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4550 - accuracy: 0.7640 - val_loss: 0.5081 - val_accuracy: 0.7434\n",
      "Epoch 17/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4391 - accuracy: 0.7840 - val_loss: 0.5899 - val_accuracy: 0.7146\n",
      "Epoch 18/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4506 - accuracy: 0.7710 - val_loss: 0.5268 - val_accuracy: 0.7482\n",
      "Epoch 19/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4474 - accuracy: 0.7650 - val_loss: 0.5333 - val_accuracy: 0.7170\n",
      "Epoch 20/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4330 - accuracy: 0.7800 - val_loss: 0.5064 - val_accuracy: 0.7530\n",
      "Epoch 20: early stopping\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Nadam(learning_rate=0.01)\n",
    "\n",
    "# If multiclass, use \"sparse_categorical_crossentropy\" as the loss function\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(train_x, train_target, epochs=50,\n",
    "                    validation_data=(test_x, test_target), callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9094948172569275, 0.7314148545265198]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_target, verbose=0)\n",
    "\n",
    "scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.91\n",
      "accuracy: 73.14%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predictions are probabilities.\n",
    "\n",
    "predictions = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.]], dtype=float32)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rounding the probabilities determines 1 or 0\n",
    "\n",
    "np.round(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[153,  57],\n",
       "       [ 55, 152]], dtype=int64)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(test_target, np.round(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a simple RNN with two or more layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 12\n",
    "n_inputs = 1\n",
    "\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.SimpleRNN(32, return_sequences=True, input_shape=[n_steps, n_inputs] ),\n",
    "    keras.layers.SimpleRNN(32, return_sequences=True),\n",
    "    keras.layers.SimpleRNN(32), \n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "32/32 [==============================] - 2s 21ms/step - loss: 0.6017 - accuracy: 0.6720 - val_loss: 0.5896 - val_accuracy: 0.7026\n",
      "Epoch 2/20\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.5362 - accuracy: 0.7300 - val_loss: 0.5479 - val_accuracy: 0.7050\n",
      "Epoch 3/20\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.5102 - accuracy: 0.7390 - val_loss: 0.5189 - val_accuracy: 0.7194\n",
      "Epoch 4/20\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.4819 - accuracy: 0.7400 - val_loss: 0.5079 - val_accuracy: 0.7146\n",
      "Epoch 5/20\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.4852 - accuracy: 0.7500 - val_loss: 0.5789 - val_accuracy: 0.7050\n",
      "Epoch 6/20\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.4852 - accuracy: 0.7460 - val_loss: 0.5189 - val_accuracy: 0.7434\n",
      "Epoch 7/20\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.4954 - accuracy: 0.7320 - val_loss: 0.5459 - val_accuracy: 0.7098\n",
      "Epoch 8/20\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.4708 - accuracy: 0.7460 - val_loss: 0.4985 - val_accuracy: 0.7218\n",
      "Epoch 9/20\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.4626 - accuracy: 0.7600 - val_loss: 0.5859 - val_accuracy: 0.6978\n",
      "Epoch 10/20\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.4797 - accuracy: 0.7750 - val_loss: 0.5223 - val_accuracy: 0.7122\n",
      "Epoch 11/20\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.4670 - accuracy: 0.7570 - val_loss: 0.5186 - val_accuracy: 0.7338\n",
      "Epoch 12/20\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.4911 - accuracy: 0.7530 - val_loss: 0.5202 - val_accuracy: 0.7266\n",
      "Epoch 13/20\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.4388 - accuracy: 0.7810 - val_loss: 0.5087 - val_accuracy: 0.7458\n",
      "Epoch 13: early stopping\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(30)\n",
    "tf.random.set_seed(30)\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=0.01)\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_x, train_target, epochs=20,\n",
    "                   validation_data = (test_x, test_target), callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5087302923202515, 0.7458033561706543]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_target, verbose=0)\n",
    "\n",
    "scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.51\n",
      "accuracy: 74.58%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a LSTM with one layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 12\n",
    "n_inputs = 1\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    \n",
    "    keras.layers.LSTM(32, input_shape=[n_steps, n_inputs]),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "32/32 [==============================] - 1s 12ms/step - loss: 0.4412 - accuracy: 0.7700 - val_loss: 0.5032 - val_accuracy: 0.7458\n",
      "Epoch 2/20\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4410 - accuracy: 0.7750 - val_loss: 0.5023 - val_accuracy: 0.7482\n",
      "Epoch 3/20\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4409 - accuracy: 0.7750 - val_loss: 0.5023 - val_accuracy: 0.7482\n",
      "Epoch 4/20\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4410 - accuracy: 0.7750 - val_loss: 0.5019 - val_accuracy: 0.7458\n",
      "Epoch 5/20\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4408 - accuracy: 0.7720 - val_loss: 0.5021 - val_accuracy: 0.7482\n",
      "Epoch 6/20\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4411 - accuracy: 0.7730 - val_loss: 0.5017 - val_accuracy: 0.7482\n",
      "Epoch 7/20\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4407 - accuracy: 0.7740 - val_loss: 0.5014 - val_accuracy: 0.7482\n",
      "Epoch 8/20\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4411 - accuracy: 0.7700 - val_loss: 0.5017 - val_accuracy: 0.7482\n",
      "Epoch 9/20\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4406 - accuracy: 0.7740 - val_loss: 0.5020 - val_accuracy: 0.7482\n",
      "Epoch 10/20\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4404 - accuracy: 0.7720 - val_loss: 0.5017 - val_accuracy: 0.7482\n",
      "Epoch 11/20\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4406 - accuracy: 0.7750 - val_loss: 0.5013 - val_accuracy: 0.7458\n",
      "Epoch 12/20\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4403 - accuracy: 0.7770 - val_loss: 0.5015 - val_accuracy: 0.7458\n",
      "Epoch 13/20\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4404 - accuracy: 0.7750 - val_loss: 0.5016 - val_accuracy: 0.7482\n",
      "Epoch 14/20\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4401 - accuracy: 0.7750 - val_loss: 0.5017 - val_accuracy: 0.7482\n",
      "Epoch 15/20\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4400 - accuracy: 0.7750 - val_loss: 0.5016 - val_accuracy: 0.7482\n",
      "Epoch 16/20\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4400 - accuracy: 0.7770 - val_loss: 0.5016 - val_accuracy: 0.7482\n",
      "Epoch 16: early stopping\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(57)\n",
    "tf.random.set_seed(57)\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=0.0001)\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_x, train_target, epochs=20,\n",
    "                   validation_data = (test_x, test_target), callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5016409158706665, 0.7482014298439026]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_target, verbose=0)\n",
    "\n",
    "scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.50\n",
      "accuracy: 74.82%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a LSTM with two or more layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 12\n",
    "n_inputs = 1\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.LSTM(32, return_sequences=True, input_shape=[n_steps, n_inputs]),\n",
    "    keras.layers.LSTM(32, return_sequences=True),\n",
    "    keras.layers.LSTM(32),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "32/32 [==============================] - 1s 12ms/step - loss: 0.4445 - accuracy: 0.7730 - val_loss: 0.5002 - val_accuracy: 0.7458\n",
      "Epoch 2/20\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4421 - accuracy: 0.7770 - val_loss: 0.4996 - val_accuracy: 0.7530\n",
      "Epoch 3/20\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4410 - accuracy: 0.7770 - val_loss: 0.5004 - val_accuracy: 0.7482\n",
      "Epoch 4/20\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4421 - accuracy: 0.7790 - val_loss: 0.5020 - val_accuracy: 0.7410\n",
      "Epoch 5/20\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4399 - accuracy: 0.7750 - val_loss: 0.4986 - val_accuracy: 0.7482\n",
      "Epoch 6/20\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4381 - accuracy: 0.7760 - val_loss: 0.5018 - val_accuracy: 0.7482\n",
      "Epoch 7/20\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4388 - accuracy: 0.7710 - val_loss: 0.5005 - val_accuracy: 0.7458\n",
      "Epoch 8/20\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4379 - accuracy: 0.7770 - val_loss: 0.4988 - val_accuracy: 0.7458\n",
      "Epoch 9/20\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4369 - accuracy: 0.7770 - val_loss: 0.4983 - val_accuracy: 0.7482\n",
      "Epoch 10/20\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4390 - accuracy: 0.7750 - val_loss: 0.4987 - val_accuracy: 0.7554\n",
      "Epoch 11/20\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4399 - accuracy: 0.7750 - val_loss: 0.4978 - val_accuracy: 0.7530\n",
      "Epoch 12/20\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4345 - accuracy: 0.7880 - val_loss: 0.4983 - val_accuracy: 0.7626\n",
      "Epoch 13/20\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4357 - accuracy: 0.7790 - val_loss: 0.4986 - val_accuracy: 0.7482\n",
      "Epoch 14/20\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4345 - accuracy: 0.7830 - val_loss: 0.4960 - val_accuracy: 0.7722\n",
      "Epoch 15/20\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4329 - accuracy: 0.7870 - val_loss: 0.4943 - val_accuracy: 0.7650\n",
      "Epoch 16/20\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4311 - accuracy: 0.7820 - val_loss: 0.5001 - val_accuracy: 0.7626\n",
      "Epoch 17/20\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4315 - accuracy: 0.7850 - val_loss: 0.5045 - val_accuracy: 0.7626\n",
      "Epoch 18/20\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4324 - accuracy: 0.7820 - val_loss: 0.4960 - val_accuracy: 0.7458\n",
      "Epoch 19/20\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.7820 - val_loss: 0.4938 - val_accuracy: 0.7650\n",
      "Epoch 20/20\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4271 - accuracy: 0.7840 - val_loss: 0.4939 - val_accuracy: 0.7578\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(89)\n",
    "tf.random.set_seed(89)\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=0.001)\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_x, train_target, epochs=20,\n",
    "                   validation_data = (test_x, test_target), callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.49387261271476746, 0.7577937841415405]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_target, verbose=0)\n",
    "\n",
    "scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.49\n",
      "accuracy: 75.78%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a GRU with one layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 12\n",
    "n_inputs = 1\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.GRU(32, input_shape=[n_steps, n_inputs]),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "32/32 [==============================] - 1s 12ms/step - loss: 0.4319 - accuracy: 0.7720 - val_loss: 0.4886 - val_accuracy: 0.7626\n",
      "Epoch 2/20\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4215 - accuracy: 0.7890 - val_loss: 0.4981 - val_accuracy: 0.7554\n",
      "Epoch 3/20\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4234 - accuracy: 0.7870 - val_loss: 0.5279 - val_accuracy: 0.7554\n",
      "Epoch 4/20\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4145 - accuracy: 0.8040 - val_loss: 0.5141 - val_accuracy: 0.7458\n",
      "Epoch 5/20\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4152 - accuracy: 0.8080 - val_loss: 0.5382 - val_accuracy: 0.7242\n",
      "Epoch 6/20\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4199 - accuracy: 0.7870 - val_loss: 0.5002 - val_accuracy: 0.7578\n",
      "Epoch 6: early stopping\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(34)\n",
    "tf.random.set_seed(34)\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=0.01)\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_x, train_target, epochs=20,\n",
    "                   validation_data = (test_x, test_target), callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.500237762928009, 0.7577937841415405]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_target, verbose=0)\n",
    "\n",
    "scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.50\n",
      "accuracy: 75.78%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a GRU with two or more layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 12\n",
    "n_inputs = 1\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.GRU(32, return_sequences=True, input_shape=[n_steps, n_inputs]),\n",
    "    keras.layers.GRU(32, return_sequences=True),\n",
    "    keras.layers.GRU(32),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "32/32 [==============================] - 3s 25ms/step - loss: 0.3840 - accuracy: 0.8260 - val_loss: 0.5002 - val_accuracy: 0.7626\n",
      "Epoch 2/20\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.3782 - accuracy: 0.8260 - val_loss: 0.5002 - val_accuracy: 0.7626\n",
      "Epoch 3/20\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3749 - accuracy: 0.8200 - val_loss: 0.5003 - val_accuracy: 0.7578\n",
      "Epoch 4/20\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3734 - accuracy: 0.8320 - val_loss: 0.5033 - val_accuracy: 0.7602\n",
      "Epoch 5/20\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.3672 - accuracy: 0.8250 - val_loss: 0.5039 - val_accuracy: 0.7530\n",
      "Epoch 6/20\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3680 - accuracy: 0.8290 - val_loss: 0.5078 - val_accuracy: 0.7530\n",
      "Epoch 6: early stopping\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(75)\n",
    "tf.random.set_seed(75)\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=0.001)\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_x, train_target, epochs=20,\n",
    "                   validation_data = (test_x, test_target), callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.507764995098114, 0.7529975771903992]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_target, verbose=0)\n",
    "\n",
    "scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.51\n",
      "accuracy: 75.30%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "nav_menu": {},
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
